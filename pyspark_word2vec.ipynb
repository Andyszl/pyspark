{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand \n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('word2vec').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df=spark.read.csv('Movie_reviews.csv',inferSchema=True,header=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据清洗\n",
    "text_df=text_df.filter(((text_df.Sentiment =='1') | (text_df.Sentiment =='0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6990, 2)\n"
     ]
    }
   ],
   "source": [
    "print((text_df.count(),len(text_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签转换\n",
    "text_df = text_df.withColumn(\"Label\", text_df.Sentiment.cast('float')).drop('Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+-----+\n",
      "|Review                                                                  |Label|\n",
      "+------------------------------------------------------------------------+-----+\n",
      "|by the way, the Da Vinci Code sucked, just letting you know...          |0.0  |\n",
      "|Brokeback Mountain was an AWESOME movie.                                |1.0  |\n",
      "|DA VINCI CODE IS AWESOME!!                                              |1.0  |\n",
      "|the people who are worth it know how much i love the da vinci code.     |1.0  |\n",
      "|Brokeback Mountain is fucking horrible..                                |0.0  |\n",
      "|I love Brokeback Mountain.                                              |1.0  |\n",
      "|Mission Impossible 3 was excellent.                                     |1.0  |\n",
      "|mission impossible 2 rocks!!....                                        |1.0  |\n",
      "|Murderball-Immediately after Crash won the Oscar, there was a lot of bul|0.0  |\n",
      "|I heard Da Vinci Code sucked pretty hard, which is too bad, because I li|0.0  |\n",
      "+------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df.orderBy(rand()).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=text_df.withColumn('Review', regexp_replace(col('Review'), \"\\\\.\", \"\")).withColumn('Review', regexp_replace(col('Review'), \"\\\\!\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+-----+\n",
      "|Review                                                                  |Label|\n",
      "+------------------------------------------------------------------------+-----+\n",
      "|As I sit here, watching the MTV Movie Awards, I am reminded of how much |0.0  |\n",
      "|I am a Christian and I absolutely HATE the Da Vinci Code                |0.0  |\n",
      "|* Mission Impossible III is an absolutely awesome possum movie          |1.0  |\n",
      "|I, too, like Harry Potter                                               |1.0  |\n",
      "|I hated The Da Vinci Code                                               |0.0  |\n",
      "|I love The Da Vinci Code                                                |1.0  |\n",
      "|I am going to start reading the Harry Potter series again because that i|1.0  |\n",
      "|The Da Vinci Code was awesome, I can't wait to read it                  |1.0  |\n",
      "|Because I would like to make friends who like the same things I like, an|1.0  |\n",
      "|Always knows what I want, not guy crazy, hates Harry Potter             |0.0  |\n",
      "+------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(rand()).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization=Tokenizer(inputCol='Review',outputCol='tokens')\n",
    "tokenized_df=tokenization.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|              Review|Label|              tokens|\n",
      "+--------------------+-----+--------------------+\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|\n",
      "|this was the firs...|  1.0|[this, was, the, ...|\n",
      "|i liked the Da Vi...|  1.0|[i, liked, the, d...|\n",
      "|i liked the Da Vi...|  1.0|[i, liked, the, d...|\n",
      "|I liked the Da Vi...|  1.0|[i, liked, the, d...|\n",
      "|that's not even a...|  1.0|[that's, not, eve...|\n",
      "|I loved the Da Vi...|  1.0|[i, loved, the, d...|\n",
      "|i thought da vinc...|  1.0|[i, thought, da, ...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|\n",
      "|I thought the Da ...|  1.0|[i, thought, the,...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|\n",
      "|then I turn on th...|  1.0|[then, i, turn, o...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|\n",
      "|i love da vinci code|  1.0|[i, love, da, vin...|\n",
      "|i loved da vinci ...|  1.0|[i, loved, da, vi...|\n",
      "|TO NIGHT:: THE DA...|  1.0|[to, night::, the...|\n",
      "|THE DA VINCI CODE...|  1.0|[the, da, vinci, ...|\n",
      "|Thing is, I enjoy...|  1.0|[thing, is,, i, e...|\n",
      "|very da vinci cod...|  1.0|[very, da, vinci,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=20, minCount=0, inputCol=\"tokens\", outputCol=\"Vec\")\n",
    "model = word2Vec.fit(tokenized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      word|              vector|\n",
      "+----------+--------------------+\n",
      "| forgotten|[0.06974968314170...|\n",
      "|   speaker|[0.02460335753858...|\n",
      "|  terrible|[0.08723274618387...|\n",
      "|     mpreg|[-0.0167238153517...|\n",
      "|     looks|[0.07572395354509...|\n",
      "|   firstly|[0.02391334623098...|\n",
      "|      movi|[0.00823700334876...|\n",
      "|  scenario|[-0.0231255926191...|\n",
      "|     ideas|[-0.0085466019809...|\n",
      "|    esther|[0.01806709542870...|\n",
      "|      used|[-0.0273626651614...|\n",
      "|       eye|[0.00155626796185...|\n",
      "|     bikes|[0.01246209908276...|\n",
      "| reference|[-0.0011805207468...|\n",
      "| beautiful|[0.11400406062602...|\n",
      "|\"christmas|[0.00261365668848...|\n",
      "|    playin|[0.02212674915790...|\n",
      "|    sunday|[-0.0196329616010...|\n",
      "|     funny|[-0.0205662474036...|\n",
      "| precious,|[-0.0075996569357...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectors = model.getVectors()\n",
    "vectors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|              Review|Label|              tokens|                 Vec|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|[-0.4523605648428...|\n",
      "|this was the firs...|  1.0|[this, was, the, ...|[-0.0664692324732...|\n",
      "|i liked the Da Vi...|  1.0|[i, liked, the, d...|[-0.3672762550413...|\n",
      "|i liked the Da Vi...|  1.0|[i, liked, the, d...|[-0.3672762550413...|\n",
      "|I liked the Da Vi...|  1.0|[i, liked, the, d...|[-0.2843162438521...|\n",
      "|that's not even a...|  1.0|[that's, not, eve...|[0.02557325368564...|\n",
      "|I loved the Da Vi...|  1.0|[i, loved, the, d...|[-0.1331588972492...|\n",
      "|i thought da vinc...|  1.0|[i, thought, da, ...|[-0.4282118374566...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|[-0.3809949652188...|\n",
      "|I thought the Da ...|  1.0|[i, thought, the,...|[-0.3003517504442...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|[-0.3208075933424...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|[-0.1684188649058...|\n",
      "|then I turn on th...|  1.0|[then, i, turn, o...|[-0.1241637165037...|\n",
      "|The Da Vinci Code...|  1.0|[the, da, vinci, ...|[-0.5829711806561...|\n",
      "|i love da vinci code|  1.0|[i, love, da, vin...|[-0.8626178264617...|\n",
      "|i loved da vinci ...|  1.0|[i, loved, da, vi...|[-0.6781160801649...|\n",
      "|TO NIGHT:: THE DA...|  1.0|[to, night::, the...|[-0.3154515451751...|\n",
      "|THE DA VINCI CODE...|  1.0|[the, da, vinci, ...|[-0.3223142419010...|\n",
      "|Thing is, I enjoy...|  1.0|[thing, is,, i, e...|[-0.3657021539402...|\n",
      "|very da vinci cod...|  1.0|[very, da, vinci,...|[-0.5341845141457...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(tokenized_df)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text_df=result.select(['Vec','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=['Vec'],outputCol='features_vec')\n",
    "model_text_df = df_assembler.transform(model_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Vec: vector (nullable = true)\n",
      " |-- Label: float (nullable = true)\n",
      " |-- features_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_text_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df,test_df=model_text_df.randomSplit([0.75,0.25])\n",
    "log_reg=LogisticRegression(featuresCol='features_vec',labelCol='Label').fit(training_df)\n",
    "results=log_reg.evaluate(test_df).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=MulticlassClassificationEvaluator(labelCol='Label',metricName='accuracy').evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440885264997088"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(i,model,data):\n",
    "    word2Vec_2 = Word2Vec(vectorSize=i, minCount=0, inputCol=\"tokens\", outputCol=\"result\")\n",
    "    result = word2Vec_2.fit(data).transform(data)\n",
    "    model_text_df=result.select(['result','Label'])\n",
    "    df_assembler = VectorAssembler(inputCols=['result'],outputCol='features_vec')\n",
    "    model_text_df = df_assembler.transform(model_text_df)\n",
    "    training_df,test_df=model_text_df.randomSplit([0.75,0.25])\n",
    "    log_reg=model(featuresCol='features_vec',labelCol='Label').fit(training_df)\n",
    "    results=log_reg.evaluate(test_df).predictions\n",
    "    accuracy=MulticlassClassificationEvaluator(labelCol='Label',metricName='accuracy').evaluate(results)\n",
    "    print(i,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9556926528323051\n",
      "30 0.952755905511811\n",
      "40 0.9634626194491287\n",
      "50 0.9592439456585942\n",
      "60 0.9554540262707024\n",
      "70 0.953016241299304\n",
      "80 0.968271954674221\n",
      "90 0.9595278246205734\n",
      "100 0.9607508532423208\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,101,10):\n",
    "    pipeline(i,LogisticRegression,tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9552322327923894\n",
      "30 0.9589595375722544\n",
      "40 0.96\n",
      "50 0.9654566744730679\n",
      "60 0.961560203504805\n",
      "70 0.9585253456221198\n",
      "80 0.964712578258395\n",
      "90 0.9631171921475312\n",
      "100 0.9514779698828778\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,101,10):\n",
    "    word2Vec_2 = Word2Vec(vectorSize=i, minCount=0, inputCol=\"tokens\", outputCol=\"result\")\n",
    "    result = word2Vec_2.fit(tokenized_df).transform(tokenized_df)\n",
    "    model_text_df=result.select(['result','Label'])\n",
    "    df_assembler = VectorAssembler(inputCols=['result'],outputCol='features_vec')\n",
    "    model_text_df = df_assembler.transform(model_text_df)\n",
    "    training_df,test_df=model_text_df.randomSplit([0.75,0.25])\n",
    "    log_reg=LogisticRegression(featuresCol='features_vec',labelCol='Label').fit(training_df)\n",
    "    results=log_reg.evaluate(test_df).predictions\n",
    "    accuracy=MulticlassClassificationEvaluator(labelCol='Label',metricName='accuracy').evaluate(results)\n",
    "    print(i,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n",
    "refined_df=stopword_removal.transform(tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline2(i,model,data):\n",
    "    word2Vec_2 = Word2Vec(vectorSize=i, minCount=0, inputCol=\"refined_tokens\", outputCol=\"result\")\n",
    "    result = word2Vec_2.fit(data).transform(data)\n",
    "    model_text_df=result.select(['result','Label'])\n",
    "    df_assembler = VectorAssembler(inputCols=['result'],outputCol='features_vec')\n",
    "    model_text_df = df_assembler.transform(model_text_df)\n",
    "    training_df,test_df=model_text_df.randomSplit([0.75,0.25])\n",
    "    log_reg=model(featuresCol='features_vec',labelCol='Label').fit(training_df)\n",
    "    results=log_reg.evaluate(test_df).predictions\n",
    "    accuracy=MulticlassClassificationEvaluator(labelCol='Label',metricName='accuracy').evaluate(results)\n",
    "    print(i,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9464594127806563\n",
      "30 0.9586636466591166\n",
      "40 0.9636982416335791\n",
      "50 0.9536878216123499\n",
      "60 0.9547255234861347\n",
      "70 0.9580941446613088\n",
      "80 0.952018724400234\n",
      "90 0.95475910693302\n",
      "100 0.9651094027202839\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,101,10):\n",
    "    pipeline(i,LogisticRegression,refined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
